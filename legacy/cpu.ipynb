{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas matplotlib seaborn numpy glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "def load_metrics(scenario):\n",
    "    \"\"\"Load CPU and memory metrics for a specific scenario.\"\"\"\n",
    "    # Find all metric files for the scenario\n",
    "    files = glob.glob(f\"performance_logs/{scenario}/*_metrics.csv\")\n",
    "    \n",
    "    # Load and combine data\n",
    "    dfs = []\n",
    "    for file in files:\n",
    "        df = pd.read_csv(file)\n",
    "        df['Scenario'] = scenario\n",
    "        dfs.append(df)\n",
    "    \n",
    "    if not dfs:\n",
    "        return None\n",
    "    \n",
    "    # Combine all dataframes\n",
    "    return pd.concat(dfs)\n",
    "\n",
    "def analyze_memory_consumption(scenarios=[\"small\", \"medium\", \"full\"]):\n",
    "    \"\"\"Analyze and visualize memory consumption across scenarios.\"\"\"\n",
    "    # Load data for all scenarios\n",
    "    data = []\n",
    "    for scenario in scenarios:\n",
    "        df = load_metrics(scenario)\n",
    "        if df is not None:\n",
    "            data.append(df)\n",
    "    \n",
    "    if not data:\n",
    "        print(\"No data found!\")\n",
    "        return\n",
    "    \n",
    "    # Combine all scenario data\n",
    "    all_data = pd.concat(data)\n",
    "    \n",
    "    # Convert timestamp to datetime\n",
    "    all_data['Timestamp'] = pd.to_datetime(all_data['Timestamp'])\n",
    "    \n",
    "    # Extract agent type from AgentId\n",
    "    all_data['AgentType'] = all_data['AgentId'].apply(\n",
    "        lambda x: 'Professor' if 'Profesor' in x else \n",
    "                  'Room' if 'Sala' in x else \n",
    "                  'Supervisor' if 'Supervisor' in x else 'Other')\n",
    "    \n",
    "    # Create figure for memory analysis\n",
    "    fig = plt.figure(figsize=(15, 12))\n",
    "    gs = GridSpec(3, 2, figure=fig)\n",
    "    \n",
    "    # 1. Memory Usage Time Series\n",
    "    ax1 = fig.add_subplot(gs[0, :])\n",
    "    \n",
    "    for scenario, scenario_data in all_data.groupby('Scenario'):\n",
    "        # Normalize timestamps to start from 0\n",
    "        base_time = scenario_data['Timestamp'].min()\n",
    "        scenario_data = scenario_data.copy()\n",
    "        scenario_data['RelativeTime'] = (scenario_data['Timestamp'] - base_time).dt.total_seconds()\n",
    "        \n",
    "        # Group by time bins and agent type\n",
    "        time_bins = np.linspace(0, scenario_data['RelativeTime'].max(), 100)\n",
    "        scenario_data['TimeBin'] = pd.cut(scenario_data['RelativeTime'], time_bins)\n",
    "        \n",
    "        # Calculate average memory usage per time bin and agent type\n",
    "        avg_mem = scenario_data.groupby(['TimeBin', 'AgentType'])['MemoryUsagePercent'].mean().reset_index()\n",
    "        \n",
    "        # Plot data\n",
    "        for agent_type, agent_data in avg_mem.groupby('AgentType'):\n",
    "            ax1.plot(\n",
    "                agent_data['TimeBin'].apply(lambda x: x.mid), \n",
    "                agent_data['MemoryUsagePercent'],\n",
    "                label=f\"{scenario} - {agent_type}\"\n",
    "            )\n",
    "    \n",
    "    ax1.set_xlabel('Time (seconds)')\n",
    "    ax1.set_ylabel('Memory Usage (%)')\n",
    "    ax1.set_title('Memory Usage Over Time by Agent Type and Scenario')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    # 2. Memory vs CPU Usage Scatter Plot\n",
    "    ax2 = fig.add_subplot(gs[1, 0])\n",
    "    \n",
    "    scatter = ax2.scatter(\n",
    "        all_data['CPUUsage'],\n",
    "        all_data['MemoryUsagePercent'],\n",
    "        c=all_data['Scenario'].astype('category').cat.codes,\n",
    "        alpha=0.6,\n",
    "        s=50,\n",
    "        cmap='viridis'\n",
    "    )\n",
    "    \n",
    "    # Add legend\n",
    "    legend1 = ax2.legend(\n",
    "        scatter.legend_elements()[0], \n",
    "        all_data['Scenario'].unique(),\n",
    "        title=\"Scenario\"\n",
    "    )\n",
    "    ax2.add_artist(legend1)\n",
    "    \n",
    "    ax2.set_xlabel('CPU Usage (%)')\n",
    "    ax2.set_ylabel('Memory Usage (%)')\n",
    "    ax2.set_title('Memory Usage vs CPU Usage')\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    # 3. Memory Usage Distribution\n",
    "    ax3 = fig.add_subplot(gs[1, 1])\n",
    "    \n",
    "    for scenario, scenario_data in all_data.groupby('Scenario'):\n",
    "        sns.kdeplot(\n",
    "            data=scenario_data, \n",
    "            x='MemoryUsagePercent', \n",
    "            label=scenario,\n",
    "            ax=ax3\n",
    "        )\n",
    "    \n",
    "    ax3.set_xlabel('Memory Usage (%)')\n",
    "    ax3.set_ylabel('Density')\n",
    "    ax3.set_title('Memory Usage Distribution by Scenario')\n",
    "    ax3.legend()\n",
    "    ax3.grid(True)\n",
    "    \n",
    "    # 4. Memory Usage by Agent Type\n",
    "    ax4 = fig.add_subplot(gs[2, 0])\n",
    "    \n",
    "    sns.barplot(\n",
    "        data=all_data, \n",
    "        x='AgentType', \n",
    "        y='UsedMemory', \n",
    "        hue='Scenario',\n",
    "        ax=ax4\n",
    "    )\n",
    "    \n",
    "    ax4.set_xlabel('Agent Type')\n",
    "    ax4.set_ylabel('Used Memory (bytes)')\n",
    "    ax4.set_title('Memory Usage by Agent Type')\n",
    "    ax4.grid(True, axis='y')\n",
    "    \n",
    "    # 5. Memory Efficiency\n",
    "    ax5 = fig.add_subplot(gs[2, 1])\n",
    "    \n",
    "    # Calculate memory efficiency (higher is better)\n",
    "    # This is an example - you might define efficiency differently\n",
    "    # For example, memory per assigned task or processed message\n",
    "    \n",
    "    # Let's use a simple metric: number of messages processed per MB of memory\n",
    "    # (You would need to add this data to your metrics)\n",
    "    # This is a placeholder - the real calculation depends on your data structure\n",
    "    \n",
    "    # Sample calculation assuming message count is available\n",
    "    if 'MessagesProcessed' in all_data.columns:\n",
    "        all_data['MemoryEfficiency'] = all_data['MessagesProcessed'] / (all_data['UsedMemory'] / (1024 * 1024))\n",
    "        \n",
    "        sns.boxplot(\n",
    "            data=all_data, \n",
    "            x='Scenario', \n",
    "            y='MemoryEfficiency',\n",
    "            ax=ax5\n",
    "        )\n",
    "        \n",
    "        ax5.set_xlabel('Scenario')\n",
    "        ax5.set_ylabel('Messages per MB')\n",
    "        ax5.set_title('Memory Efficiency by Scenario')\n",
    "        ax5.grid(True, axis='y')\n",
    "    else:\n",
    "        ax5.text(0.5, 0.5, 'Efficiency metric not available', \n",
    "                 horizontalalignment='center', verticalalignment='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('memory_analysis.png')\n",
    "    print(\"Memory analysis visualizations saved.\")\n",
    "\n",
    "# Extension for thread bottleneck analysis\n",
    "def analyze_thread_bottlenecks(scenarios=[\"small\", \"medium\", \"full\"]):\n",
    "    \"\"\"Analyze thread-level bottlenecks across scenarios.\"\"\"\n",
    "    # Load thread data for all scenarios\n",
    "    thread_data = []\n",
    "    \n",
    "    for scenario in scenarios:\n",
    "        files = glob.glob(f\"performance_logs/{scenario}/*_thread.csv\")\n",
    "        for file in files:\n",
    "            df = pd.read_csv(file)\n",
    "            df['Scenario'] = scenario\n",
    "            thread_data.append(df)\n",
    "    \n",
    "    if not thread_data:\n",
    "        print(\"No thread data found!\")\n",
    "        return\n",
    "    \n",
    "    # Combine all thread data\n",
    "    all_thread_data = pd.concat(thread_data)\n",
    "    \n",
    "    # Convert timestamp to datetime\n",
    "    all_thread_data['Timestamp'] = pd.to_datetime(all_thread_data['Timestamp'])\n",
    "    \n",
    "    # Categorize threads by name pattern\n",
    "    def categorize_thread(name):\n",
    "        if 'Profesor' in name:\n",
    "            return 'Professor Agent'\n",
    "        elif 'Sala' in name:\n",
    "            return 'Room Agent'\n",
    "        elif 'Supervisor' in name:\n",
    "            return 'Supervisor Agent'\n",
    "        elif 'Messaging' in name or 'ACL' in name:\n",
    "            return 'Messaging'\n",
    "        elif 'DF' in name or 'Directory' in name:\n",
    "            return 'Directory Services'\n",
    "        elif 'GC' in name:\n",
    "            return 'Garbage Collection'\n",
    "        else:\n",
    "            return 'Other'\n",
    "    \n",
    "    all_thread_data['ThreadCategory'] = all_thread_data['ThreadName'].apply(categorize_thread)\n",
    "    \n",
    "    # Create figure for thread bottleneck analysis\n",
    "    fig = plt.figure(figsize=(15, 15))\n",
    "    gs = GridSpec(3, 2, figure=fig)\n",
    "    \n",
    "    # 1. Top CPU Consuming Threads\n",
    "    ax1 = fig.add_subplot(gs[0, :])\n",
    "    \n",
    "    # Get top 10 threads by CPU time\n",
    "    top_threads = all_thread_data.groupby(['ThreadName', 'ThreadCategory'])['CPUTime_ns'].sum().reset_index()\n",
    "    top_threads = top_threads.sort_values('CPUTime_ns', ascending=False).head(10)\n",
    "    \n",
    "    sns.barplot(\n",
    "        data=top_threads,\n",
    "        x='CPUTime_ns',\n",
    "        y='ThreadName',\n",
    "        hue='ThreadCategory',\n",
    "        palette='viridis',\n",
    "        ax=ax1\n",
    "    )\n",
    "    \n",
    "    ax1.set_title('Top 10 CPU Consuming Threads')\n",
    "    ax1.set_xlabel('Total CPU Time (ns)')\n",
    "    ax1.set_ylabel('Thread Name')\n",
    "    ax1.grid(True, axis='x')\n",
    "    \n",
    "    # 2. CPU Time by Thread Category\n",
    "    ax2 = fig.add_subplot(gs[1, 0])\n",
    "    \n",
    "    category_cpu = all_thread_data.groupby(['Scenario', 'ThreadCategory'])['CPUTime_ns'].sum().reset_index()\n",
    "    \n",
    "    sns.barplot(\n",
    "        data=category_cpu,\n",
    "        x='ThreadCategory',\n",
    "        y='CPUTime_ns',\n",
    "        hue='Scenario',\n",
    "        ax=ax2\n",
    "    )\n",
    "    \n",
    "    ax2.set_title('CPU Time by Thread Category')\n",
    "    ax2.set_xlabel('Thread Category')\n",
    "    ax2.set_ylabel('Total CPU Time (ns)')\n",
    "    ax2.grid(True, axis='y')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # 3. CPU Utilization Over Time\n",
    "    ax3 = fig.add_subplot(gs[1, 1])\n",
    "    \n",
    "    # Group by time and category\n",
    "    all_thread_data['TimeMinute'] = all_thread_data['Timestamp'].dt.floor('1min')\n",
    "    time_series = all_thread_data.groupby(['TimeMinute', 'ThreadCategory'])['CPUPercent'].sum().reset_index()\n",
    "    \n",
    "    # Plot CPU percentage over time by category\n",
    "    for category, cat_data in time_series.groupby('ThreadCategory'):\n",
    "        ax3.plot(\n",
    "            cat_data['TimeMinute'],\n",
    "            cat_data['CPUPercent'],\n",
    "            label=category,\n",
    "            marker='o',\n",
    "            markersize=4\n",
    "        )\n",
    "    \n",
    "    ax3.set_title('CPU Utilization by Thread Category Over Time')\n",
    "    ax3.set_xlabel('Time')\n",
    "    ax3.set_ylabel('CPU Utilization (%)')\n",
    "    ax3.legend()\n",
    "    ax3.grid(True)\n",
    "    \n",
    "    # 4. Thread Bottleneck Analysis\n",
    "    ax4 = fig.add_subplot(gs[2, 0])\n",
    "    \n",
    "    # Calculate bottleneck score = (CPU Time * CPU %) - higher means more likely a bottleneck\n",
    "    all_thread_data['BottleneckScore'] = all_thread_data['CPUTime_ns'] * all_thread_data['CPUPercent'] / 1e9\n",
    "    \n",
    "    bottleneck_data = all_thread_data.groupby(['Scenario', 'ThreadCategory'])['BottleneckScore'].mean().reset_index()\n",
    "    \n",
    "    sns.barplot(\n",
    "        data=bottleneck_data,\n",
    "        x='ThreadCategory',\n",
    "        y='BottleneckScore',\n",
    "        hue='Scenario',\n",
    "        ax=ax4\n",
    "    )\n",
    "    \n",
    "    ax4.set_title('Thread Bottleneck Analysis')\n",
    "    ax4.set_xlabel('Thread Category')\n",
    "    ax4.set_ylabel('Bottleneck Score')\n",
    "    ax4.grid(True, axis='y')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # 5. User Time vs CPU Time\n",
    "    ax5 = fig.add_subplot(gs[2, 1])\n",
    "    \n",
    "    # Calculate ratio of user time to CPU time\n",
    "    all_thread_data['UserRatio'] = all_thread_data['UserTime_ns'] / all_thread_data['CPUTime_ns']\n",
    "    all_thread_data['UserRatio'].replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    all_thread_data.dropna(subset=['UserRatio'], inplace=True)\n",
    "    \n",
    "    sns.boxplot(\n",
    "        data=all_thread_data,\n",
    "        x='ThreadCategory',\n",
    "        y='UserRatio',\n",
    "        ax=ax5\n",
    "    )\n",
    "    \n",
    "    ax5.set_title('User Time vs CPU Time by Thread Category')\n",
    "    ax5.set_xlabel('Thread Category')\n",
    "    ax5.set_ylabel('User Time / CPU Time Ratio')\n",
    "    ax5.grid(True, axis='y')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('thread_bottleneck_analysis.png')\n",
    "    print(\"Thread bottleneck analysis visualizations saved.\")\n",
    "\n",
    "# Execute both analyses\n",
    "if __name__ == \"__main__\":\n",
    "    analyze_memory_consumption()\n",
    "    analyze_thread_bottlenecks()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
